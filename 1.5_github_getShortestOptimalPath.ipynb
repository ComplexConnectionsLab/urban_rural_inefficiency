{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5077c2ca-63ff-4b6d-b9c1-0c42461c4d2e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce6cb474-bc63-43bd-8a5c-9606c355708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from geopy.distance import great_circle\n",
    "import geohash\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "import math\n",
    "import contextily as cx\n",
    "from shapely.geometry import Polygon,Point\n",
    "from shapely import wkt,ops\n",
    "import colorsys\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import spatial\n",
    "import random\n",
    "from datetime import datetime\n",
    "import pointpats \n",
    "import pandana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1b1ca0b-1fb7-4708-8998-18a1ba764d0b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6831ac5a-614c-4dac-a498-fb0d434de268",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c365d670-28da-4fb3-b9eb-f77763a93f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_name = 'colombia'\n",
    "country_abbrv = 'co'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b77158-ca7f-4470-abac-5a1674694167",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "daily_od_fname = f'od_{country_abbrv}_agg5_3h.csv'\n",
    "daily_od = pd.read_csv(daily_od_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8134cc9-00f9-4440-aeb0-fcdc1b434626",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_times = list(np.unique([row.local_time[-19:] for i, row in daily_od.iterrows()]))\n",
    "str_time_dict = {t:i for i, t in enumerate(unique_times)}\n",
    "daily_od['time_id'] = daily_od.local_time.apply(lambda x: str_time_dict[x[-19:]])\n",
    "daily_od['local_date'] = daily_od.local_date.astype(str).apply(lambda x: datetime.strptime(x, \"%Y%m%d\"))\n",
    "daily_od['neighbours'] = daily_od['start_geohash5'].apply(lambda x: geohash.neighbors(x))\n",
    "daily_od['wtd_length']= daily_od.m_length_m * daily_od.trip_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a60e9703-5b41-4fc7-8e82-16e26a694826",
   "metadata": {},
   "outputs": [],
   "source": [
    "geohashes = list(set(daily_od.start_geohash5.unique()).union(set(daily_od.end_geohash5.unique())))\n",
    "geohash_coord = {gh:geohash.decode(gh) for gh in geohashes}\n",
    "geohash_bbox = {gh: geohash.bbox(gh) for gh in geohashes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "266cd26a-eb7a-43cd-8982-ef89ecb1f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_gdf = gpd.GeoDataFrame([[gh, Polygon([(geohash_bbox[gh]['w'], geohash_bbox[gh]['s']),\n",
    "                                     (geohash_bbox[gh]['e'], geohash_bbox[gh]['s']),\n",
    "                                     (geohash_bbox[gh]['e'], geohash_bbox[gh]['n']), \n",
    "                                     (geohash_bbox[gh]['w'], geohash_bbox[gh]['n'])])] for gh in geohashes],\n",
    "                       columns=['gh5', 'geometry'], geometry='geometry', crs=\"EPSG:4326\")\n",
    "bbox_dict = {gh:Polygon([(geohash_bbox[gh]['w'], geohash_bbox[gh]['s']),\n",
    "                                     (geohash_bbox[gh]['e'], geohash_bbox[gh]['s']),\n",
    "                                     (geohash_bbox[gh]['e'], geohash_bbox[gh]['n']), \n",
    "                                     (geohash_bbox[gh]['w'], geohash_bbox[gh]['n'])]) for gh in geohashes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79d3e9cb-8d47-4512-9f57-f1f8a2e37132",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import reverse_geocode\n",
    "\n",
    "def is_land(lat, lon):\n",
    "    location = reverse_geocode.search([(lat, lon)])[0]\n",
    "    return 'country' in location  # If the location contains a 'country', it's on land"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8ec51c-03e9-4db9-a736-ce90a1620980",
   "metadata": {},
   "source": [
    "# Get Road Network for Entire Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec9174e-9d38-4423-9b9d-79cfe3db1795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(bbox, chunk_size):\n",
    "    min_lon, min_lat, max_lon, max_lat = bbox\n",
    "    lon_steps = np.arange(min_lon, max_lon, chunk_size)\n",
    "    lat_steps = np.arange(min_lat, max_lat, chunk_size)\n",
    "    chunks = []\n",
    "    for lon in lon_steps:\n",
    "        for lat in lat_steps:\n",
    "            chunks.append([lon, lat, lon + chunk_size, lat + chunk_size])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a921c3b3-06d4-469e-8649-e20c6f542d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_bbox={\n",
    "    'colombia':[-78.97,-4.22,-66.17,12.49],\n",
    "    'mexico':[-118.6,14.39,-86.49,32.72],\n",
    "    'india':[67.95,6.55,97.4,35.67],\n",
    "}\n",
    "\n",
    "country_projCRS={\n",
    "    'mexico': 'epsg:6362',\n",
    "    'colombia': 'epsg:9377',  \n",
    "    'india': 'epsg:24378'     \n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0311612d-b41b-42d7-8ef1-d276f0ae4ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrosm import OSM\n",
    "bounds = country_bbox[country_name]  \n",
    "\n",
    "osm = OSM(f'{country_name}_road_network.osm.pbf')\n",
    "graph_nodes, graph_edges = osm.get_network(nodes=True, network_type='driving', bounding_box=bounds)\n",
    "\n",
    "graph_nodes = graph_nodes.reset_index()\n",
    "graph_edges = graph_edges.reset_index()\n",
    "\n",
    "# Spatial join to assign gh5 to each node\n",
    "graph_nodes = gpd.sjoin(graph_nodes, bbox_gdf[['gh5', 'geometry']], how='left', predicate='within')\n",
    "\n",
    "gh5_osmid = {i: row.osmid for i, row in graph_nodes.groupby('gh5').agg({'osmid': lambda x: list(x)}).iterrows()}\n",
    "\n",
    "graph_nodes = graph_nodes.set_index('osmid')\n",
    "\n",
    "graph_edges = graph_edges[['u','v','key', 'geometry', 'length','maxspeed']]\n",
    "\n",
    "graph_edges = graph_edges.drop_duplicates(subset=['u','v'])\n",
    "graph_edges['u'] = graph_edges['u'].astype(int)\n",
    "graph_edges['v'] = graph_edges['v'].astype(int)\n",
    "\n",
    "graph_edges = graph_edges[(graph_edges['u'].isin(graph_nodes.index)) & (graph_edges['v'].isin(graph_nodes.index))]\n",
    "graph_nodes = graph_nodes[(graph_nodes.index.isin(graph_edges.u)) | (graph_nodes.index.isin(graph_edges.v))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12d04be1-41cf-4385-a00d-ca5186bfb407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>street_count</th>\n",
       "      <th>highway</th>\n",
       "      <th>ref</th>\n",
       "      <th>geometry</th>\n",
       "      <th>index_right</th>\n",
       "      <th>gh5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>osmid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5747784382</th>\n",
       "      <td>3.945557</td>\n",
       "      <td>-70.606245</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-70.60624 3.94556)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5747930240</th>\n",
       "      <td>3.628122</td>\n",
       "      <td>-70.322200</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-70.32220 3.62812)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5747932474</th>\n",
       "      <td>3.928625</td>\n",
       "      <td>-70.570909</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-70.57091 3.92862)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6140934888</th>\n",
       "      <td>3.625660</td>\n",
       "      <td>-70.324619</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-70.32462 3.62566)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6140934889</th>\n",
       "      <td>3.623476</td>\n",
       "      <td>-70.324124</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-70.32412 3.62348)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11968312895</th>\n",
       "      <td>1.802609</td>\n",
       "      <td>-78.793283</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-78.79328 1.80261)</td>\n",
       "      <td>208.0</td>\n",
       "      <td>d0rfr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11968312896</th>\n",
       "      <td>1.802755</td>\n",
       "      <td>-78.793375</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-78.79338 1.80276)</td>\n",
       "      <td>208.0</td>\n",
       "      <td>d0rfr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11968312953</th>\n",
       "      <td>1.802338</td>\n",
       "      <td>-78.793284</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-78.79328 1.80234)</td>\n",
       "      <td>208.0</td>\n",
       "      <td>d0rfr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11968312955</th>\n",
       "      <td>1.802432</td>\n",
       "      <td>-78.793529</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-78.79353 1.80243)</td>\n",
       "      <td>208.0</td>\n",
       "      <td>d0rfr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11968312991</th>\n",
       "      <td>1.802771</td>\n",
       "      <td>-78.792303</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-78.79230 1.80277)</td>\n",
       "      <td>208.0</td>\n",
       "      <td>d0rfr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1445057 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    y          x  street_count highway  ref  \\\n",
       "osmid                                                         \n",
       "5747784382   3.945557 -70.606245             3     NaN  NaN   \n",
       "5747930240   3.628122 -70.322200             3     NaN  NaN   \n",
       "5747932474   3.928625 -70.570909             3     NaN  NaN   \n",
       "6140934888   3.625660 -70.324619             1     NaN  NaN   \n",
       "6140934889   3.623476 -70.324124             3     NaN  NaN   \n",
       "...               ...        ...           ...     ...  ...   \n",
       "11968312895  1.802609 -78.793283             3     NaN  NaN   \n",
       "11968312896  1.802755 -78.793375             1     NaN  NaN   \n",
       "11968312953  1.802338 -78.793284             3     NaN  NaN   \n",
       "11968312955  1.802432 -78.793529             1     NaN  NaN   \n",
       "11968312991  1.802771 -78.792303             1     NaN  NaN   \n",
       "\n",
       "                              geometry  index_right    gh5  \n",
       "osmid                                                       \n",
       "5747784382   POINT (-70.60624 3.94556)          NaN    NaN  \n",
       "5747930240   POINT (-70.32220 3.62812)          NaN    NaN  \n",
       "5747932474   POINT (-70.57091 3.92862)          NaN    NaN  \n",
       "6140934888   POINT (-70.32462 3.62566)          NaN    NaN  \n",
       "6140934889   POINT (-70.32412 3.62348)          NaN    NaN  \n",
       "...                                ...          ...    ...  \n",
       "11968312895  POINT (-78.79328 1.80261)        208.0  d0rfr  \n",
       "11968312896  POINT (-78.79338 1.80276)        208.0  d0rfr  \n",
       "11968312953  POINT (-78.79328 1.80234)        208.0  d0rfr  \n",
       "11968312955  POINT (-78.79353 1.80243)        208.0  d0rfr  \n",
       "11968312991  POINT (-78.79230 1.80277)        208.0  d0rfr  \n",
       "\n",
       "[1445057 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f98ea123-44e4-4fea-807e-2d023d8c0b79",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating contraction hierarchies with 110 threads.\n",
      "Setting CH node vector of size 1445057\n",
      "Setting CH edge vector of size 3654712\n",
      "Range graph removed 3408412 edges of 7309424\n",
      ". 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n"
     ]
    }
   ],
   "source": [
    "pnda_nx = pandana.Network(graph_nodes.x, graph_nodes.y, graph_edges.u, graph_edges.v, graph_edges[['length']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbf8249-5ac5-4289-9f73-135e3647525f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Estimated Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "619e11d2-6343-4ccc-b4da-d27ac119f155",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_estimated_routes(real_df, gh5_osmid, iterations=100, sample_street=True):\n",
    "    \n",
    "    graph_points_df = []\n",
    "    for iter_i in range(iterations):\n",
    "        print(iter_i, end='\\r')\n",
    "        for i,row in real_df.iterrows():\n",
    "    \n",
    "            ### SAMPLE STREET NX POINTS ###\n",
    "            if (row.start_geohash5 in gh5_osmid.keys()) and (row.end_geohash5 in gh5_osmid.keys()):\n",
    "                points_og = random.choices(gh5_osmid[row.start_geohash5], k=row.trip_count)\n",
    "                points_dest = random.choices(gh5_osmid[row.end_geohash5], k=row.trip_count)\n",
    "                for o,d in zip(points_og, points_dest):\n",
    "                    graph_points_df += [[row.start_geohash5, row.end_geohash5, row.local_date, row.time_id, o,d, iter_i]]\n",
    "        \n",
    "    graph_points_df = pd.DataFrame(graph_points_df, columns=['start_geohash5', 'end_geohash5', 'local_date', 'time_id', 'origin', 'destination', 'iteration'])\n",
    "    return graph_points_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3271cf6e-8611-4c22-829f-6a7ef22f102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_route_efficiency(real_df, filter_times, filter_dates, gh5_osmid, iterations=100):\n",
    "    estimated_df = []\n",
    "    for ft, fd in list(itertools.product(filter_times,filter_dates)):\n",
    "        print('Fetching estimates for', str(fd)[:10], 'at', ft )\n",
    "        filtered_df = real_df[(real_df.local_date==str(fd)[:10]) & (real_df.time_id==int(ft))]\n",
    "        estimated_df.append(get_estimated_routes(filtered_df, gh5_osmid, iterations=iterations))\n",
    "    estimated_df = pd.concat(estimated_df)\n",
    "    return estimated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "386574f4-fceb-40e9-a1df-c885da24f66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_weekday = {d:d.weekday() < 5 for d in daily_od.local_date.unique()}\n",
    "weekday_dates = [k for k,v in date_weekday.items() if v]\n",
    "weekend_dates = [k for k,v in date_weekday.items() if not v]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83473e1d-4531-4620-b361-5c19c6a9508d",
   "metadata": {},
   "source": [
    "## Estimated Routes for Agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "20037675-0b16-475a-8917-9889db370b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_geohash5</th>\n",
       "      <th>end_geohash5</th>\n",
       "      <th>time_id</th>\n",
       "      <th>trip_count</th>\n",
       "      <th>m_length_m</th>\n",
       "      <th>sd_length_m</th>\n",
       "      <th>local_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d0rfr</td>\n",
       "      <td>d0rfr</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2585.309754</td>\n",
       "      <td>3152.957604</td>\n",
       "      <td>agg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d0rfr</td>\n",
       "      <td>d0rfr</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>1781.322595</td>\n",
       "      <td>3466.759242</td>\n",
       "      <td>agg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d0rfr</td>\n",
       "      <td>d0rfr</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>1756.129379</td>\n",
       "      <td>1961.445673</td>\n",
       "      <td>agg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d0rfr</td>\n",
       "      <td>d0rfr</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>4665.225628</td>\n",
       "      <td>8826.063073</td>\n",
       "      <td>agg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d0rfr</td>\n",
       "      <td>d0rfr</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>1466.432141</td>\n",
       "      <td>1820.371835</td>\n",
       "      <td>agg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  start_geohash5 end_geohash5  time_id  trip_count   m_length_m  sd_length_m  \\\n",
       "0          d0rfr        d0rfr        2          14  2585.309754  3152.957604   \n",
       "1          d0rfr        d0rfr        3          17  1781.322595  3466.759242   \n",
       "2          d0rfr        d0rfr        4          15  1756.129379  1961.445673   \n",
       "3          d0rfr        d0rfr        5          16  4665.225628  8826.063073   \n",
       "4          d0rfr        d0rfr        6          15  1466.432141  1820.371835   \n",
       "\n",
       "  local_date  \n",
       "0        agg  \n",
       "1        agg  \n",
       "2        agg  \n",
       "3        agg  \n",
       "4        agg  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_weekday_od = daily_od[daily_od.local_date.isin(weekday_dates)]\n",
    "agg_weekday_od = agg_weekday_od.groupby(['start_geohash5','end_geohash5','time_id']).agg({'trip_count':'mean',\n",
    "                                                                                          'm_length_m':'mean',\n",
    "                                                                                          'sd_length_m':'mean'}).reset_index()\n",
    "agg_weekday_od['trip_count'] = agg_weekday_od['trip_count'].round().astype(int)\n",
    "agg_weekday_od['local_date']  = 'agg'\n",
    "agg_weekday_od.head()\n",
    "\n",
    "agg_weekend_od = daily_od[daily_od.local_date.isin(weekend_dates)]\n",
    "agg_weekend_od = agg_weekend_od.groupby(['start_geohash5','end_geohash5','time_id']).agg({'trip_count':'mean',\n",
    "                                                                                          'm_length_m':'mean',\n",
    "                                                                                          'sd_length_m':'mean'}).reset_index()\n",
    "agg_weekend_od['trip_count'] = agg_weekend_od['trip_count'].round().astype(int)\n",
    "agg_weekend_od['local_date']  = 'agg'\n",
    "agg_weekend_od.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "948ed3a7-8023-4dc0-9134-4c4895112750",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching estimates for agg at 0\n",
      "Fetching estimates for agg at 1\n",
      "Fetching estimates for agg at 2\n",
      "Fetching estimates for agg at 3\n",
      "Fetching estimates for agg at 4\n",
      "Fetching estimates for agg at 5\n",
      "Fetching estimates for agg at 6\n",
      "Fetching estimates for agg at 7\n",
      "Fetching estimates for agg at 0\n",
      "Fetching estimates for agg at 1\n",
      "Fetching estimates for agg at 2\n",
      "Fetching estimates for agg at 3\n",
      "Fetching estimates for agg at 4\n",
      "Fetching estimates for agg at 5\n",
      "Fetching estimates for agg at 6\n",
      "Fetching estimates for agg at 7\n",
      "99\r"
     ]
    }
   ],
   "source": [
    "agg_weekend_eff = get_route_efficiency(agg_weekend_od, list(str_time_dict.values()), \n",
    "                                       ['agg'], gh5_osmid)\n",
    "\n",
    "agg_weekday_eff = get_route_efficiency(agg_weekday_od, list(str_time_dict.values()), \n",
    "                                       ['agg'], gh5_osmid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0a0dd5d1-fdba-48f7-8ea3-6a058b4f2c2c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "agg_weekend_eff['sp_lengths'] = pnda_nx.shortest_path_lengths(agg_weekend_eff.origin, \n",
    "                                                              agg_weekend_eff.destination, imp_name='length')\n",
    "\n",
    "agg_weekday_eff['sp_lengths'] = pnda_nx.shortest_path_lengths(agg_weekday_eff.origin, \n",
    "                                                              agg_weekday_eff.destination, imp_name='length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6873aa1a-9f97-433b-9a28-2f7125f3560a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "agg_weekend_eff.to_csv('estimated_routes/'+country_abbrv+'_agg_weekend_eff.csv')\n",
    "agg_weekday_eff.to_csv('estimated_routes/'+country_abbrv+'_agg_weekday_eff.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d976c4d-d2a0-4f35-acaf-6033c5b16d78",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Calculate Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf1cef58-3344-4a36-9b3b-2970975948e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_efficiency_random(real_data, estimated_data, urbanicity_df):\n",
    "    local_dates = list(estimated_data.local_date.unique())\n",
    "    local_times = list(estimated_data.time_id.unique())\n",
    "    # print(local_dates, local_times)\n",
    "    \n",
    "    filtered_rd = real_data[(real_data.local_date.isin(local_dates)) & (real_data.time_id.isin(local_times))]\n",
    "    R = filtered_rd.groupby(['start_geohash5','local_date','time_id']).agg({'trip_count':'sum', \n",
    "                                                                            'wtd_length':'sum'}).reset_index()\n",
    "    R['avg_len_real'] = R['wtd_length']/R['trip_count']\n",
    "    E = estimated_data.groupby(['start_geohash5','local_date', \n",
    "                                'time_id', 'iteration']).agg({'sp_lengths':'mean', \n",
    "                                                              'origin':'count'}).reset_index().rename({'origin':'trip_count'},\n",
    "                                                                                                      axis=1) \n",
    "    E = E.groupby(['start_geohash5','local_date','time_id']).agg({'sp_lengths':'mean','trip_count':'mean'}).reset_index()\n",
    "\n",
    "    delta_df = R[['start_geohash5','avg_len_real', 'time_id', 'local_date',\n",
    "                  'trip_count']].rename({'start_geohash5':'gh5'},\n",
    "                                        axis=1).merge(bbox_gdf, how='left', on='gh5')\n",
    "    delta_df = E.drop('trip_count',axis=1).rename({'start_geohash5':'gh5', \n",
    "                                      'sp_lengths':'avg_len_est'}, \n",
    "                                                  axis=1).merge(delta_df, how='left', on=['gh5', 'local_date', 'time_id'])\n",
    "    delta_df['delta'] = delta_df.avg_len_real - delta_df.avg_len_est \n",
    "    delta_df = delta_df.merge(urbanicity_df, how='left', on='gh5')\n",
    "    return delta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "464c0e0f-d65b-4f29-843f-5059335de7be",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_efficiency_agg(real_data, estimated_data, urbanicity_df, local_dates):\n",
    "    # local_dates = list(estimated_data.local_date.unique())\n",
    "    local_times = list(estimated_data.time_id.unique())\n",
    "    print(local_dates, local_times)\n",
    "    \n",
    "    filtered_rd = real_data[(real_data.local_date.isin(local_dates)) & (real_data.time_id.isin(local_times))]\n",
    "    R = filtered_rd.groupby(['start_geohash5', 'end_geohash5', 'time_id']).agg({'trip_count':'mean',\n",
    "                                                                                'wtd_length':'mean'}).reset_index()\n",
    "    \n",
    "    R = R.groupby(['start_geohash5','time_id']).agg({'trip_count':'sum', 'wtd_length':'sum'}).reset_index()\n",
    "    R['trip_count'] = R['trip_count'].round().astype(int)\n",
    "\n",
    "    R['avg_len_real'] = R['wtd_length']/R['trip_count']\n",
    "    E = estimated_data.groupby(['start_geohash5','end_geohash5',\n",
    "                                'time_id']).agg({'sp_lengths':'mean', \n",
    "                                                              'origin':'count'}).reset_index().rename({'origin':'trip_count'},\n",
    "                                                                                                      axis=1)\n",
    "    E['wtd_length'] = E['sp_lengths']*E['trip_count']\n",
    "    E = E.groupby(['start_geohash5','time_id']).agg({'wtd_length':'sum','trip_count':'sum'}).reset_index()\n",
    "    E['avg_len_est'] = E['wtd_length']/E['trip_count']\n",
    "    \n",
    "    delta_df = R[['start_geohash5','avg_len_real', 'time_id', \n",
    "                  'trip_count']].rename({'start_geohash5':'gh5'},\n",
    "                                        axis=1).merge(bbox_gdf, how='left', on='gh5')\n",
    "    delta_df = E.drop(['trip_count','wtd_length'],axis=1).rename({'start_geohash5':'gh5'}, \n",
    "                                                  axis=1).merge(delta_df, how='left', on=['gh5', 'time_id'])\n",
    "    delta_df['delta'] = delta_df.avg_len_real - delta_df.avg_len_est \n",
    "    delta_df = delta_df.merge(urbanicity_df, how='left', on='gh5')\n",
    "    return delta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eee7c832-a713-4df1-8a91-25f271084465",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter-niyer/README\n"
     ]
    }
   ],
   "source": [
    "urbanicity_df = pd.read_csv(f'{country_abbrv}_urbanicity_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d41223a8-7abd-49db-8c0d-459b8e685cc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Timestamp('2019-11-01 00:00:00'), Timestamp('2019-11-04 00:00:00'), Timestamp('2019-11-05 00:00:00'), Timestamp('2019-11-06 00:00:00'), Timestamp('2019-11-07 00:00:00'), Timestamp('2019-11-08 00:00:00'), Timestamp('2019-11-11 00:00:00'), Timestamp('2019-11-12 00:00:00'), Timestamp('2019-11-13 00:00:00'), Timestamp('2019-11-14 00:00:00'), Timestamp('2019-11-15 00:00:00'), Timestamp('2019-11-18 00:00:00'), Timestamp('2019-11-19 00:00:00'), Timestamp('2019-11-20 00:00:00'), Timestamp('2019-11-21 00:00:00'), Timestamp('2019-11-22 00:00:00'), Timestamp('2019-11-25 00:00:00'), Timestamp('2019-11-26 00:00:00'), Timestamp('2019-11-27 00:00:00'), Timestamp('2019-11-28 00:00:00'), Timestamp('2019-11-29 00:00:00'), Timestamp('2019-12-02 00:00:00'), Timestamp('2019-12-03 00:00:00'), Timestamp('2019-12-04 00:00:00'), Timestamp('2019-12-05 00:00:00'), Timestamp('2019-12-06 00:00:00'), Timestamp('2019-12-09 00:00:00'), Timestamp('2019-12-10 00:00:00'), Timestamp('2019-12-11 00:00:00'), Timestamp('2019-12-12 00:00:00'), Timestamp('2019-12-13 00:00:00'), Timestamp('2019-12-16 00:00:00'), Timestamp('2019-12-17 00:00:00'), Timestamp('2019-12-18 00:00:00'), Timestamp('2019-12-19 00:00:00'), Timestamp('2019-12-20 00:00:00'), Timestamp('2019-12-23 00:00:00'), Timestamp('2019-12-24 00:00:00'), Timestamp('2019-12-25 00:00:00'), Timestamp('2019-12-26 00:00:00'), Timestamp('2019-12-27 00:00:00'), Timestamp('2019-12-30 00:00:00'), Timestamp('2019-12-31 00:00:00')] [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "[Timestamp('2019-11-02 00:00:00'), Timestamp('2019-11-03 00:00:00'), Timestamp('2019-11-09 00:00:00'), Timestamp('2019-11-10 00:00:00'), Timestamp('2019-11-16 00:00:00'), Timestamp('2019-11-17 00:00:00'), Timestamp('2019-11-23 00:00:00'), Timestamp('2019-11-24 00:00:00'), Timestamp('2019-11-30 00:00:00'), Timestamp('2019-12-01 00:00:00'), Timestamp('2019-12-07 00:00:00'), Timestamp('2019-12-08 00:00:00'), Timestamp('2019-12-14 00:00:00'), Timestamp('2019-12-15 00:00:00'), Timestamp('2019-12-21 00:00:00'), Timestamp('2019-12-22 00:00:00'), Timestamp('2019-12-28 00:00:00'), Timestamp('2019-12-29 00:00:00')] [0, 1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "eff_agg_weekday = get_efficiency_agg(daily_od, agg_weekday_eff,urbanicity_df, weekday_dates)\n",
    "eff_agg_weekend = get_efficiency_agg(daily_od, agg_weekend_eff,urbanicity_df, weekend_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b8bd84-665c-4d3d-ac2e-d380f341d967",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eff_agg_weekend.to_csv('estimated_routes/'+country_abbrv+'_agg_weekend_eff_final.csv')\n",
    "eff_agg_weekday.to_csv('estimated_routes/'+country_abbrv+'_agg_weekday_eff_final.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
